{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8ycG9+M9DW+7XHqfHcsGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamagami/is2024/blob/main/13_Transformer_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization using a pre-trained Transformer model\n",
        "This is a task of summarizing text using a pre-trained model.\n",
        "Since the pre-trained model is loaded during the initial startup, it may take some time.\n"
      ],
      "metadata": {
        "id": "nLe_9_PQlRdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Kv1GrjFalxJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVwWavgZl1aK",
        "outputId": "2588bf2d-10df-487d-e544-0878b6472a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data (a long text passage)\n",
        "text = \"\"\"\n",
        "The transformer model is a neural network architecture that was introduced in the paper 'Attention is All You Need'\n",
        "by Vaswani et al. It uses self-attention mechanisms to process input data efficiently, making it particularly suited\n",
        "for tasks like natural language processing and machine translation. Unlike traditional RNNs and LSTMs, transformers\n",
        "do not rely on sequential data processing. This allows them to handle long-range dependencies and parallelize\n",
        "computation, leading to significant improvements in performance and training speed. Over the years, transformer models\n",
        "have become the backbone of state-of-the-art models like BERT, GPT, and T5, which have revolutionized applications\n",
        "like language understanding, text generation, and summarization.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "lnfroYall0gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate a summary\n",
        "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "\n",
        "# Display the results\n",
        "print(\"Original Text:\\n\", text)\n",
        "print(\"\\nGenerated Summary:\\n\", summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOTVi9o6lv_3",
        "outputId": "9d8ac884-c937-4940-aab9-847522da92c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " \n",
            "The transformer model is a neural network architecture that was introduced in the paper 'Attention is All You Need'\n",
            "by Vaswani et al. It uses self-attention mechanisms to process input data efficiently, making it particularly suited\n",
            "for tasks like natural language processing and machine translation. Unlike traditional RNNs and LSTMs, transformers\n",
            "do not rely on sequential data processing. This allows them to handle long-range dependencies and parallelize\n",
            "computation, leading to significant improvements in performance and training speed. Over the years, transformer models\n",
            "have become the backbone of state-of-the-art models like BERT, GPT, and T5, which have revolutionized applications\n",
            "like language understanding, text generation, and summarization.\n",
            "\n",
            "\n",
            "Generated Summary:\n",
            " Transformers use self-attention mechanisms to process input data efficiently. Unlike traditional RNNs and LSTMs, transformers do not rely on sequential data processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FPpKfd2lMd3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}